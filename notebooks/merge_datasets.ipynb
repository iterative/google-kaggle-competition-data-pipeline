{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fiftyone import ViewField as F\n",
    "from pathlib import Path\n",
    "\n",
    "from dataset_utils.download_utils import prepare_dataset\n",
    "from dataset_utils.fiftyone_load_utils import load_dataset, split_and_export_manifest\n",
    "from dataset_utils.fiftyone_export_utils import merge_datasets, export_manifest, create_absolute_paths_in_manifest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the datasets to your local folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify which datasets you want to download. Note that dataset_names must be equal to the datasets in https://github.com/iterative/google-kaggle-competition-data-pipeline/tree/main/datasets\n",
    "\n",
    "dataset_names=[\"food_101_small\", \"freiburg_groceries\"]\n",
    "dataset_path=Path(\"../datasets/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in dataset_names:\n",
    "    prepare_dataset(dataset_name=dataset_name,\n",
    "                    output_path=dataset_path/dataset_name\n",
    "                    )\n",
    "\n",
    "# In case you would like to donwload only certain partitions, you specify them in the list\n",
    "#prepare_dataset(dataset_name=dataset_name, output_path=dataset_path, partitions=[0, 1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |█████████████| 10100/10100 [5.8s elapsed, 0s remaining, 1.7K samples/s]        \n",
      " 100% |███████████████| 4947/4947 [2.9s elapsed, 0s remaining, 1.7K samples/s]      \n"
     ]
    }
   ],
   "source": [
    "dataset_food_101 = load_dataset(dataset_name=dataset_names[0],\n",
    "                                dataset_path=dataset_path/dataset_names[0],\n",
    "                                rewrite=True,\n",
    "                                print_test=False)\n",
    "dataset_freiburg = load_dataset(dataset_name=dataset_names[1],\n",
    "                                dataset_path=dataset_path/dataset_names[1],\n",
    "                                rewrite=True,\n",
    "                                print_test=False\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now you do filtering and changes to the invidual datasets that you need.\n",
    "You may get inspired by some of these functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_food_101 = (\n",
    "    dataset_food_101\n",
    "    .map_labels(\"ground_truth\", {\"spaghetti_carbonara\": \"spaghetti\", \"spaghetti_bolognese\": \"spaghetti\"})\n",
    ")\n",
    "\n",
    "view_only_pizza = (\n",
    "    view_food_101\n",
    "    .filter_labels(\"ground_truth\", F(\"label\").is_in(['pizza']))\n",
    ")\n",
    "\n",
    "# This function replaces original label in ground_truth.label with new label. This means that all images will have the same single label.\n",
    "view_freiburg = (\n",
    "    dataset_freiburg\n",
    "    .set_field(\"ground_truth.label\", \"packaged_goods\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge and output datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = merge_datasets([view_food_101, view_freiburg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'caesar_salad': 100, 'hot_and_sour_soup': 100, 'dumplings': 100, 'caprese_salad': 100, 'beignets': 100, 'fish_and_chips': 100, 'beef_carpaccio': 100, 'scallops': 100, 'grilled_salmon': 100, 'fried_rice': 100, 'sushi': 100, 'frozen_yogurt': 100, 'sashimi': 100, 'crab_cakes': 100, 'breakfast_burrito': 100, 'lobster_roll_sandwich': 100, 'hummus': 100, 'creme_brulee': 100, 'steak': 100, 'croque_madame': 100, 'cannoli': 100, 'peking_duck': 100, 'churros': 100, 'ceviche': 100, 'hot_dog': 100, 'packaged_goods': 4947, 'cheese_plate': 100, 'huevos_rancheros': 100, 'seaweed_salad': 100, 'chicken_wings': 100, 'cup_cakes': 100, 'baklava': 100, 'mussels': 100, 'macaroni_and_cheese': 100, 'french_onion_soup': 100, 'chicken_quesadilla': 100, 'ravioli': 100, 'chicken_curry': 100, 'foie_gras': 100, 'filet_mignon': 100, 'risotto': 100, 'pork_chop': 100, 'ice_cream': 100, 'poutine': 100, 'club_sandwich': 100, 'tiramisu': 100, 'clam_chowder': 100, 'grilled_cheese_sandwich': 100, 'baby_back_ribs': 100, 'ramen': 100, 'french_toast': 100, 'panna_cotta': 100, 'falafel': 100, 'cheesecake': 100, 'lasagna': 100, 'gyoza': 100, 'carrot_cake': 100, 'guacamole': 100, 'nachos': 100, 'macarons': 100, 'french_fries': 100, 'donuts': 100, 'garlic_bread': 100, 'beef_tartare': 100, 'chocolate_cake': 100, 'fried_calamari': 100, 'apple_pie': 100, 'bibimbap': 100, 'bread_pudding': 100, 'eggs_benedict': 100, 'lobster_bisque': 100, 'deviled_eggs': 100, 'edamame': 100, 'pizza': 100, 'spaghetti': 200, 'takoyaki': 100, 'greek_salad': 100, 'samosa': 100, 'tuna_tartare': 100, 'strawberry_shortcake': 100, 'waffles': 100, 'pancakes': 100, 'oysters': 100, 'paella': 100, 'prime_rib': 100, 'onion_rings': 100, 'hamburger': 100, 'shrimp_and_grits': 100, 'pho': 100, 'beet_salad': 100, 'pulled_pork_sandwich': 100, 'omelette': 100, 'tacos': 100, 'chocolate_mousse': 100, 'gnocchi': 100, 'red_velvet_cake': 100, 'bruschetta': 100, 'miso_soup': 100, 'pad_thai': 100, 'escargots': 100, 'spring_rolls': 100}\n"
     ]
    }
   ],
   "source": [
    "# Final check that the datasets are merged correctly\n",
    "\n",
    "print(dataset.count_values('ground_truth.label'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export dataset either with absolute or relative paths\n",
    "\n",
    "Use relative=False (default) for absolute paths - in case you want to train with this dataset on your local computer\n",
    "\n",
    "Use relative=True for relative paths - in case you want to share this dataset with someone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |█████████████| 15047/15047 [6.4s elapsed, 0s remaining, 2.6K samples/s]        \n"
     ]
    }
   ],
   "source": [
    "export_manifest(dataset, export_dir=Path(\"../data/merged_dataset/\"), relative=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternatively, you may also split the dataset and then export it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |███████████████| 9028/9028 [3.6s elapsed, 0s remaining, 3.2K samples/s]        \n",
      " 100% |███████████████| 3010/3010 [1.7s elapsed, 0s remaining, 2.4K samples/s]       \n",
      " 100% |███████████████| 3009/3009 [1.5s elapsed, 0s remaining, 1.7K samples/s]         \n"
     ]
    }
   ],
   "source": [
    "split_and_export_manifest(dataset, export_dir=Path(\"../data/merged_dataset/\"), relative=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing relative paths to absolute paths\n",
    "In case, you would like to change the relative paths back to absolute paths, you need to specify absolute paths to the datasets folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path_dic = {}\n",
    "dataset_path_dic[\"food_101_small\"] = \"/workspaces/google-kaggle-competition/datasets/food_101_small\"\n",
    "dataset_path_dic[\"freiburg_groceries\"] = \"/workspaces/google-kaggle-competition/datasets/freiburg_groceries\"\n",
    "\n",
    "create_absolute_paths_in_manifest(dataset_path_dic=dataset_path_dic, input_manifest_path=Path(\"../data/merged_dataset/manifest.json\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f946df053fbf2b937619d3c5458e7af74262f9a954d8797ba0b27400bcafe06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
